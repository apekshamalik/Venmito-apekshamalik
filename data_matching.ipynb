{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Matching & Linking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge people data from JSON and YAML sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_people_data(people_json_df, people_yml_df):\n",
    "    \"\"\"Merges people data from JSON and YAML sources into a single DataFrame.\"\"\"\n",
    "    people_yml_df.rename(columns={\"phone\": \"telephone\", \"email\": \"email\"}, inplace=True)\n",
    "    people_yml_df[['city', 'country']] = people_yml_df['city'].str.split(', ', expand=True)\n",
    "    people_yml_df[['first_name', 'last_name']] = people_yml_df['name'].str.split(n=1, expand=True)\n",
    "    people_yml_df['last_name'] = people_yml_df['last_name'].fillna('')\n",
    "    people_yml_df['id'] = people_yml_df['id'].astype(str).str.zfill(4)\n",
    "    \n",
    "    merged_df = pd.merge(\n",
    "        people_json_df, \n",
    "        people_yml_df, \n",
    "        on=['id', 'email', 'telephone'], \n",
    "        how='outer', \n",
    "        suffixes=('_json', '_yml')\n",
    "    )\n",
    "    \n",
    "    merged_df['first_name'] = merged_df['first_name_json'].fillna(merged_df['first_name_yml'])\n",
    "    merged_df['last_name'] = merged_df['last_name_json'].fillna(merged_df['last_name_yml'])\n",
    "    merged_df.drop(columns=['first_name_json', 'first_name_yml', 'last_name_json', 'last_name_yml'], inplace=True)\n",
    "    merged_df['country'] = merged_df['country'].fillna('Unknown')\n",
    "    \n",
    "    print(\"\\npeople_df Columns After Cleanup:\", merged_df.columns.tolist())\n",
    "    \n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link promotions data with people data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def link_promotions(people_df, promotions_df):\n",
    "    \"\"\"Links promotions data with people data using email as the key and includes additional details.\"\"\"\n",
    "    \n",
    "    # Standardize email formatting (strip spaces, lowercase)\n",
    "    promotions_df['client_email'] = promotions_df['client_email'].str.strip().str.lower()\n",
    "    people_df['email'] = people_df['email'].str.strip().str.lower()\n",
    "    \n",
    "    # Rename for merging\n",
    "    promotions_df = promotions_df.rename(columns={\"client_email\": \"email\"})\n",
    "    \n",
    "    # Merge promotions with people\n",
    "    promotions_linked_df = pd.merge(\n",
    "        promotions_df, \n",
    "        people_df[['id', 'email', 'telephone', 'first_name', 'last_name', 'city', 'country']], \n",
    "        on=['email'], \n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Ensure correct 'id' column is used\n",
    "    if 'id_y' in promotions_linked_df.columns:\n",
    "        promotions_linked_df['id'] = promotions_linked_df['id_y']\n",
    "        promotions_linked_df.drop(columns=['id_x', 'id_y'], inplace=True, errors='ignore')\n",
    "\n",
    "    # Drop rows where no match was found (i.e., unknown people)\n",
    "    promotions_linked_df = promotions_linked_df.dropna(subset=['id'])\n",
    "\n",
    "    return promotions_linked_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link transactions data with people data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_transactions(people_df, transactions_df):\n",
    "    \"\"\"Links transactions data with people data using phone numbers as the key.\"\"\"\n",
    "    if transactions_df is None:\n",
    "        print(\"\\nERROR: transactions_df is None! Check XML parsing function.\")\n",
    "        return None\n",
    "    \n",
    "    if 'items' in transactions_df.columns:\n",
    "        transactions_df['items'] = transactions_df['items'].apply(lambda x: x if isinstance(x, list) else [])\n",
    "    else:\n",
    "        transactions_df['items'] = [[]] * len(transactions_df)\n",
    "    \n",
    "    print(\"\\nSample transactions_df (after fixing items column):\")\n",
    "    print(transactions_df.head())\n",
    "    \n",
    "    transactions_linked_df = transactions_df.merge(\n",
    "        people_df[['id', 'telephone']], \n",
    "        left_on=\"phone\", \n",
    "        right_on=\"telephone\", \n",
    "        how=\"left\"\n",
    "    ).drop(columns=[\"telephone\"])\n",
    "    \n",
    "    return transactions_linked_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function to link transfers data with people data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_transfers(people_df, transfers_df):\n",
    "    \"\"\"Links transfers data with people data using sender and recipient IDs, and adds country information.\"\"\"\n",
    "\n",
    "    # Ensure ID columns are strings with 4-digit format\n",
    "    transfers_df['sender_id'] = transfers_df['sender_id'].astype(str).str.zfill(4)\n",
    "    transfers_df['recipient_id'] = transfers_df['recipient_id'].astype(str).str.zfill(4)\n",
    "    people_df['id'] = people_df['id'].astype(str).str.zfill(4)\n",
    "\n",
    "    # Extract country from location dictionary\n",
    "    people_df[\"country\"] = people_df[\"location\"].apply(lambda x: x.get(\"Country\", \"Unknown\") if isinstance(x, dict) else \"Unknown\")\n",
    "\n",
    "    # Merge Sender Details (Name + Country)\n",
    "    transfers_df = transfers_df.merge(\n",
    "        people_df[['id', 'first_name', 'last_name', 'country']], \n",
    "        left_on=\"sender_id\", \n",
    "        right_on=\"id\", \n",
    "        how=\"left\"\n",
    "    ).rename(columns={\n",
    "        \"first_name\": \"sender_first_name\",\n",
    "        \"last_name\": \"sender_last_name\",\n",
    "        \"country\": \"sender_country\"\n",
    "    })\n",
    "\n",
    "    # Merge Recipient Details (Name + Country)\n",
    "    transfers_df = transfers_df.merge(\n",
    "        people_df[['id', 'first_name', 'last_name', 'country']], \n",
    "        left_on=\"recipient_id\", \n",
    "        right_on=\"id\", \n",
    "        how=\"left\"\n",
    "    ).rename(columns={\n",
    "        \"first_name\": \"recipient_first_name\",\n",
    "        \"last_name\": \"recipient_last_name\",\n",
    "        \"country\": \"recipient_country\"\n",
    "    })\n",
    "\n",
    "    # Drop duplicate ID columns after merging\n",
    "    transfers_df.drop(columns=[\"id_x\", \"id_y\"], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return transfers_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook data_matching.ipynb to script\n",
      "[NbConvertApp] Writing 5160 bytes to data_matching.py\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script data_matching.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
